{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ed4d66eb",
      "metadata": {
        "id": "ed4d66eb"
      },
      "source": [
        "\n",
        "# LLM Interface Concept\n",
        "In this notebook, we will explore the concept of creating a **unified interface** for interacting with various Large Language Models (LLMs).\n",
        "This approach makes it easier to switch between different LLMs (e.g., OpenAI, Anthropic's Claude, Cohere) using a common interface.\n",
        "\n",
        "An **interface** in programming defines a **set of methods** that a class must implement, ensuring that different implementations can be accessed in the same way.\n",
        "We will also demonstrate how LangChain handles this concept.\n",
        "\n",
        "### Key Points:\n",
        "- **Interface**: A contract that defines methods to interact with models in a unified way.\n",
        "- **Benefits**: Allows switching between LLMs without changing application code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02bf63d7",
      "metadata": {
        "id": "02bf63d7"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "\n",
        "# Define an interface (abstract class) for LLMs\n",
        "class LLMInterface(ABC):\n",
        "\n",
        "    @abstractmethod\n",
        "    def generate(self, prompt: str) -> str:\n",
        "        # Generate a response from the LLM.\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19a12d55",
      "metadata": {
        "id": "19a12d55"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "class OpenAILLM(LLMInterface):\n",
        "    def __init__(self, api_key):\n",
        "        openai.api_key = api_key\n",
        "\n",
        "    def generate(self, prompt: str) -> str:\n",
        "        response = openai.Completion.create(\n",
        "            engine=\"text-davinci-003\",\n",
        "            prompt=prompt,\n",
        "            max_tokens=150,\n",
        "            temperature=0.7\n",
        "        )\n",
        "        return response.choices[0].text.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dbb4806",
      "metadata": {
        "id": "3dbb4806"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "class ClaudeLLM(LLMInterface):\n",
        "    def __init__(self, api_key):\n",
        "        self.api_key = api_key\n",
        "        self.api_url = \"https://api.anthropic.com/v1/complete\"\n",
        "\n",
        "    def generate(self, prompt: str) -> str:\n",
        "        headers = {\n",
        "            'Authorization': f'Bearer {self.api_key}',\n",
        "            'Content-Type': 'application/json',\n",
        "        }\n",
        "        data = {\n",
        "            'prompt': prompt,\n",
        "            'model': 'claude-v1',\n",
        "            'max_tokens_to_sample': 150,\n",
        "            'temperature': 0.7,\n",
        "        }\n",
        "        response = requests.post(self.api_url, headers=headers, json=data)\n",
        "        return response.json().get('completion', \"No response\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a6da82e",
      "metadata": {
        "id": "4a6da82e"
      },
      "outputs": [],
      "source": [
        "import cohere\n",
        "\n",
        "class CohereLLM(LLMInterface):\n",
        "    def __init__(self, api_key):\n",
        "        self.client = cohere.Client(api_key)\n",
        "\n",
        "    def generate(self, prompt: str) -> str:\n",
        "        response = self.client.generate(\n",
        "            model=\"command-xlarge-nightly\",\n",
        "            prompt=prompt,\n",
        "            max_tokens=150,\n",
        "            temperature=0.7\n",
        "        )\n",
        "        return response.generations[0].text.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a74795ca",
      "metadata": {
        "id": "a74795ca"
      },
      "outputs": [],
      "source": [
        "# Choose an LLM dynamically\n",
        "def get_llm(provider, api_key):\n",
        "    if provider == \"openai\":\n",
        "        return OpenAILLM(api_key)\n",
        "    elif provider == \"claude\":\n",
        "        return ClaudeLLM(api_key)\n",
        "    elif provider == \"cohere\":\n",
        "        return CohereLLM(api_key)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid provider\")\n",
        "\n",
        "# Example usage\n",
        "llm = get_llm(\"openai\", \"YOUR_OPENAI_API_KEY\")\n",
        "response = llm.generate(\"What is artificial intelligence?\")\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3767262e",
      "metadata": {
        "id": "3767262e"
      },
      "outputs": [],
      "source": [
        "# Example with LangChain\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "# Initialize OpenAI model with API key\n",
        "llm = OpenAI(api_key=\"YOUR_OPENAI_API_KEY\")\n",
        "\n",
        "# Generate response\n",
        "response = llm(\"What is artificial intelligence?\")\n",
        "print(response)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}