{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvXFavr8uNVx"
      },
      "source": [
        "## Understanding TF-IDF (Term Frequency-Inverse Document Frequency)\n",
        "\n",
        "TF-IDF (Term Frequency-Inverse Document Frequency) is a statistical measure used in natural language processing and information retrieval to evaluate the importance of a word in a document relative to a collection of documents (corpus).\n",
        "\n",
        "Unlike simple word frequency, TF-IDF balances common and rare words to highlight the most meaningful terms.\n"
      ],
      "id": "SvXFavr8uNVx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### How TF-IDF Works?\n",
        "\n",
        "TF-IDF combines two components: **Term Frequency (TF)** and **Inverse Document Frequency (IDF)**.\n",
        "\n",
        "#### Term Frequency (TF):\n",
        "Measures how often a word appears in a document. A higher frequency suggests greater importance. If a term appears frequently in a document, it is likely relevant to the document’s content.\n",
        "\n",
        "**Formula:**\n",
        "\n",
        "TF(term, document) = (Number of times term appears in document) / (Total number of terms in the document)\n",
        "\n",
        "#### Limitations of TF Alone:\n",
        "- TF does not account for the global importance of a term across the entire corpus.\n",
        "- Common words like “the” or “and” may have high TF scores but are not meaningful in distinguishing documents.\n"
      ],
      "metadata": {
        "id": "9d5GYhK0vJ2K"
      },
      "id": "9d5GYhK0vJ2K"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fL3gk35YvU2g"
      },
      "id": "fL3gk35YvU2g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Inverse Document Frequency (IDF):\n",
        "Reduces the weight of common words across multiple documents while increasing the weight of rare words. If a term appears in fewer documents, it is more likely to be meaningful and specific.\n",
        "\n",
        "**Formula:**\n",
        "\n",
        "IDF(term, corpus) = log(Total number of documents / Number of documents containing the term)\n",
        "\n",
        "The logarithm is used to dampen the effect of very large or very small values, ensuring the IDF score scales appropriately.\n",
        "\n",
        "#### Limitations of IDF Alone:\n",
        "- IDF does not consider how often a term appears within a specific document.\n",
        "- A term might be rare across the corpus (high IDF) but irrelevant in a specific document (low TF).\n"
      ],
      "metadata": {
        "id": "ugEh5ZMivVW1"
      },
      "id": "ugEh5ZMivVW1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Converting Text into Vectors with TF-IDF: Example\n",
        "\n",
        "Imagine we have a corpus with three documents:\n",
        "\n",
        "- **Document 1**: \"The cat sat on the mat.\"\n",
        "- **Document 2**: \"The dog played in the park.\"\n",
        "- **Document 3**: \"Cats and dogs are great pets.\"\n",
        "\n",
        "Our goal is to calculate the TF-IDF score for the word \"cat\" in these documents.\n",
        "\n",
        "#### Step 1: Calculate Term Frequency (TF)\n",
        "For Document 1:\n",
        "- The word “cat” appears 1 time.\n",
        "- Total number of terms in Document 1 is 6 (“the”, “cat”, “sat”, “on”, “the”, “mat”).\n",
        "- TF(cat, Document 1) = 1/6\n",
        "\n",
        "For Document 2:\n",
        "- The word “cat” does not appear.\n",
        "- TF(cat, Document 2) = 0\n",
        "\n",
        "For Document 3:\n",
        "- The word “cat” appears 1 time (as “cats”).\n",
        "- Total number of terms in Document 3 is 6 (“cats”, “and”, “dogs”, “are”, “great”, “pets”).\n",
        "- TF(cat, Document 3) = 1/6\n",
        "\n",
        "#### Step 2: Calculate Inverse Document Frequency (IDF)\n",
        "Total number of documents in the corpus (D): 3\n",
        "Number of documents containing the term “cat”: 2 (Document 1 and Document 3).\n",
        "\n",
        "IDF(cat, D) = log(3 / 2) ≈ 0.176\n",
        "\n",
        "#### Step 3: Calculate TF-IDF\n",
        "The TF-IDF score for \"cat\" in Document 1 and Document 3 is 0.029, and 0 in Document 2.\n"
      ],
      "metadata": {
        "id": "COQER2LRvvfc"
      },
      "id": "COQER2LRvvfc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why is TF-IDF Useful in This Example?\n",
        "\n",
        "1. **Identifying Important Terms**: TF-IDF helps us understand that “cat” is important in Document 1 and Document 3 but irrelevant in Document 2. This helps in ranking documents for search engines.\n",
        "\n",
        "2. **Filtering Common Words**: Words like “the” or “and” would have high TF scores but very low IDF scores because they appear in almost all documents. Their TF-IDF scores would be close to 0, indicating they are not meaningful.\n",
        "\n",
        "3. **Highlighting Unique Terms**: If a term like “mat” appeared only in Document 1, it would have a higher IDF score, making its TF-IDF score more significant in that document.\n",
        "\n"
      ],
      "metadata": {
        "id": "C7-BvuHiw7Sl"
      },
      "id": "C7-BvuHiw7Sl"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8_L328MOxGc9"
      },
      "id": "8_L328MOxGc9"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2G2AvIHXw6s9"
      },
      "id": "2G2AvIHXw6s9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-BuvVpe1App",
        "outputId": "4b0ae728-5ff0-4838-c5f6-c07051208287"
      },
      "id": "O-BuvVpe1App",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "class TextPreprocessor:\n",
        "    def __init__(self):\n",
        "        # Initialize the stemmer and stopwords\n",
        "        self.stemmer = PorterStemmer()\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    def lowercase(self, text):\n",
        "        \"\"\"Convert text to lowercase\"\"\"\n",
        "        return text.lower()\n",
        "\n",
        "    def remove_punctuation(self, text):\n",
        "        \"\"\"Remove punctuation from the text\"\"\"\n",
        "        return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    def remove_stopwords(self, text):\n",
        "        \"\"\"Remove common stop words from the text\"\"\"\n",
        "        words = word_tokenize(text)\n",
        "        return ' '.join([word for word in words if word not in self.stop_words])\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        \"\"\"Tokenize text into words\"\"\"\n",
        "        return word_tokenize(text)\n",
        "\n",
        "    def stemming(self, text):\n",
        "        \"\"\"Apply stemming to the text\"\"\"\n",
        "        words = word_tokenize(text)\n",
        "        return ' '.join([self.stemmer.stem(word) for word in words])\n",
        "\n",
        "    def remove_numbers(self, text):\n",
        "        \"\"\"Remove numbers from the text\"\"\"\n",
        "        return re.sub(r'\\d+', '', text)\n",
        "\n",
        "    def pre_process(self, text):\n",
        "        \"\"\"Pre-process the text by applying all steps\"\"\"\n",
        "        text = self.lowercase(text)\n",
        "        text = self.remove_punctuation(text)\n",
        "        text = self.remove_stopwords(text)\n",
        "        text = self.remove_numbers(text)\n",
        "        text = self.stemming(text)\n",
        "        return text\n",
        "\n",
        "\n",
        "d0 = 'The cat sat on the mat.'\n",
        "d1 = 'The dog played in the park'\n",
        "d2 = 'Cats and dogs are great pets'\n",
        "\n",
        "# Merge documents into a single corpus\n",
        "corpus = [d0, d1, d2]\n",
        "\n",
        "# Initialize the TextPreprocessor\n",
        "preprocessor = TextPreprocessor()\n",
        "\n",
        "transformed_corpus = list(map(preprocessor.pre_process, corpus))"
      ],
      "metadata": {
        "id": "AQf8FEei0p85"
      },
      "id": "AQf8FEei0p85",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twKvv9foYedI",
        "outputId": "af9b1bd7-2f85-4096-aab4-576521499da8"
      },
      "id": "twKvv9foYedI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The cat sat on the mat.',\n",
              " 'The dog played in the park',\n",
              " 'Cats and dogs are great pets']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIFidTz9YcsI",
        "outputId": "b584c516-78f8-40e3-8113-d1ea45998231"
      },
      "id": "KIFidTz9YcsI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cat sat mat', 'dog play park', 'cat dog great pet']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjHrEVp_uNVz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f4c70a7-4686-43ea-f1d3-8a544322dde8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "IDF values:\n",
            "cat : 1.2876820724517808\n",
            "dog : 1.2876820724517808\n",
            "great : 1.6931471805599454\n",
            "mat : 1.6931471805599454\n",
            "park : 1.6931471805599454\n",
            "pet : 1.6931471805599454\n",
            "play : 1.6931471805599454\n",
            "sat : 1.6931471805599454\n"
          ]
        }
      ],
      "source": [
        "#Implementing TF-IDF in Sklearn with Python\n",
        "\n",
        "# Let's implement TF-IDF using Python's sklearn library.\n",
        "\n",
        "# Import the required module\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "# Create a TfidfVectorizer object\n",
        "tfidf = TfidfVectorizer()\n",
        "\n",
        "# Get tf-idf values\n",
        "result = tfidf.fit_transform(transformed_corpus)\n",
        "\n",
        "# Display IDF values\n",
        "print(\"\\nIDF values:\")\n",
        "for word, idf in zip(tfidf.get_feature_names_out(), tfidf.idf_):\n",
        "    print(word, \":\", idf)\n"
      ],
      "id": "XjHrEVp_uNVz"
    },
    {
      "cell_type": "code",
      "source": [
        "# get indexing\n",
        "print('\\nWord indexes:')\n",
        "print(tfidf.vocabulary_)\n",
        "\n",
        "# display tf-idf values\n",
        "print('\\ntf-idf value:')\n",
        "print(result)\n",
        "\n",
        "# in matrix form\n",
        "print('\\ntf-idf values in matrix form:')\n",
        "print(result.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bAOck6hxcLo",
        "outputId": "1e35d3fb-4d79-4e5a-a481-8a6b9ff7ce2e"
      },
      "id": "7bAOck6hxcLo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word indexes:\n",
            "{'cat': 0, 'sat': 7, 'mat': 3, 'dog': 1, 'play': 6, 'park': 4, 'great': 2, 'pet': 5}\n",
            "\n",
            "tf-idf value:\n",
            "  (0, 0)\t0.4736296010332684\n",
            "  (0, 7)\t0.6227660078332259\n",
            "  (0, 3)\t0.6227660078332259\n",
            "  (1, 1)\t0.4736296010332684\n",
            "  (1, 6)\t0.6227660078332259\n",
            "  (1, 4)\t0.6227660078332259\n",
            "  (2, 0)\t0.4280460350631185\n",
            "  (2, 1)\t0.4280460350631185\n",
            "  (2, 2)\t0.5628290964997665\n",
            "  (2, 5)\t0.5628290964997665\n",
            "\n",
            "tf-idf values in matrix form:\n",
            "[[0.4736296  0.         0.         0.62276601 0.         0.\n",
            "  0.         0.62276601]\n",
            " [0.         0.4736296  0.         0.         0.62276601 0.\n",
            "  0.62276601 0.        ]\n",
            " [0.42804604 0.42804604 0.5628291  0.         0.         0.5628291\n",
            "  0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.toarray().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFbfaJInxv1u",
        "outputId": "296eb6be-0335-49d0-fbf6-605b8d4580aa"
      },
      "id": "lFbfaJInxv1u",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tfidf.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFmdn7R4yCfq",
        "outputId": "bd77e8fa-2007-4db6-d9cf-c587f4564431"
      },
      "id": "VFmdn7R4yCfq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d0[]"
      ],
      "metadata": {
        "id": "dwkl8SLZyGl2"
      },
      "id": "dwkl8SLZyGl2",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}